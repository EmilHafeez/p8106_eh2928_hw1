---
title: "P8106 Data Science Homework 1"
author: "Emil Hafeez"
geometry: "left=2.57cm,right=2.57cm,top=2.57cm,bottom=2.57cm"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 3
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
--- 

# Section 1: Setup

## Libraries and Options

```{r libraries, include = F}
library(RNHANES)
library(tidyverse)
library(summarytools)
library(leaps)
library(ggplot2)
library(caret)
library(corrplot)
```

```{r opts chunk, include = F}
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60))

knitr::opts_chunk$set(echo = TRUE)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
```

```{r input, message = F}
train_data = read_csv("./data/solubility_train.csv")
test_data = read_csv("./data/solubility_test.csv")

set.seed(1993)
```

## Prompt

In this exercise, we will predict solubility of compounds using their chemical structures.

The training data are in the file “solubility train.csv” and the test data are in “solubil-
ity test.csv”. Among the 228 predictors, 208 are binary variables that indicate the presence

or absence of a particular chemical substructure, 16 are count features, such as the number
of bonds or the number of bromine atoms, and 4 are continuous features, such as molecular
weight or surface area. The response is in the column “Solubility” (the last column).

## Questions

(a) Fit a linear model using least squares on the training data and calculate the mean squared error using the test data.

(b) Fit a ridge regression model on the training data, with λ chosen by cross-validation. Report the test error.

(c) Fit a lasso model on the training data, with λ chosen by cross-validation. Report the test error and the number of non-zero coefficient estimates in your model.

(d) Fit a principle component regression model on the training data, with M chosen by cross-validation. Report the test error and the value of M selected by cross-validation.

(e) Which model will you choose for predicting solubility?

# Section 2: Implementation and Results

The dataframe consists of 229 variables, and it would therefore be computationally laborious to compute all or best subsets and choose that way.

Note that in performing cross-validation, you want to apply CV both when finding the predictors with the largest correlation with the response; and, you want to do it when fitting the model using only those predictors. 

There are a large number of predictors and potential collinearity (implying large variance), but a linear model is implemented to start.

```{r}
corrplot(cor(train_data), method = "circle", type = "upper")

regsubsetsObj <- regsubsets(hdl ~ ., data = train_data, method = "exhaustive", nbest = 1)

plot(regsubsetsObj, scale = "bic")
```


```{r}
set.seed(1993)
control_cv <- trainControl(method = "cv", number = 10) 

fit.lm <- train(Solubility~.,
          data = train_data,
          method = "lm",
          trControl = control_cv)
```

```{r}
#Fitting training model on test set
pred=predict(model,newdata=test)
#Calculating Accuracy
MSE=mean((test$Apps-pred)^2)
#Printing MSE
print(MSE)
```












